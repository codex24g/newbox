<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Face Recognition</title>
    <style>
        #video {
            border: 1px solid #ccc;
        }
        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            pointer-events: none; /* Make sure overlay does not block the video */
        }
        #result {
            margin-top: 10px;
        }
        .container {
            position: relative;
            width: 640px;
            height: 480px;
        }
    </style>
</head>
<body>
    <h1>Real-Time Face Recognition</h1>
    <button onclick="window.location.href='/';">Go to Image Upload</button>
    <div class="container">
        <video id="video" width="640" height="480" autoplay></video>
        <canvas id="overlay" width="640" height="480"></canvas>
    </div>
    <div id="result"></div>

    <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const resultDiv = document.getElementById('result');
        const overlayContext = overlay.getContext('2d');

        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
                video.play();
            })
            .catch(err => {
                console.error('Error accessing camera: ', err);
                resultDiv.innerHTML = `<p>Error accessing camera: ${err.message}</p>`;
            });

        async function captureFrame() {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            canvas.toBlob(async (blob) => {
                const formData = new FormData();
                formData.append('file', blob, 'frame.jpg');
                
                try {
                    const response = await fetch('/detect_faces', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) {
                        throw new Error('Network response was not ok.');
                    }

                    const data = await response.json();

                    overlayContext.clearRect(0, 0, overlay.width, overlay.height);

                    if (data.faces && data.faces.length > 0) {
                        data.faces.forEach(face => {
                            overlayContext.strokeStyle = 'red';
                            overlayContext.lineWidth = 3;
                            overlayContext.strokeRect(face.x, face.y, face.w, face.h);
                            overlayContext.fillStyle = 'red';
                            overlayContext.font = '16px Arial';
                            overlayContext.fillText(
                                `${face.name} (${face.drink_preference}, ${face.dietary_restrictions})`,
                                face.x,
                                face.y > 10 ? face.y - 5 : 10
                            );
                        });
                        resultDiv.innerHTML = `<p>${data.faces.length} face(s) detected</p>`;
                    } else {
                        resultDiv.innerHTML = `<p>No faces detected</p>`;
                    }
                } catch (error) {
                    resultDiv.innerHTML = `<p>Error in face detection: ${error.message}</p>`;
                }
            }, 'image/jpeg');
        }

        setInterval(captureFrame, 1000);
    </script>
</body>
</html>
